{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN9zLbw2O7+/j8qIhNFDp1y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Xcne_RiAqTYI"},"outputs":[],"source":["import cv2\n","import torch\n","import numpy as np\n","import os\n","import pandas as pd\n","from collections import Counter\n","from torch.utils.data import DataLoader\n","from torchvision import models, transforms\n","from PIL import Image"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/MyDrive/Colab Notebooks/DeepLearning_Final_Project_2024')\n","print(os.listdir('DeepDRiD'))\n","print(os.path.exists('./model_task_b_resnet18.pth'))\n","print(os.path.exists('./model_task_b_densenet121.pth'))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TJs6HW_pxPD0","executionInfo":{"status":"ok","timestamp":1735903440151,"user_tz":-120,"elapsed":1825,"user":{"displayName":"Amir sard","userId":"05229660649413556744"}},"outputId":"3c6f0f31-38db-4d4e-cd82-8954ecf432ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","['sample_submission.csv', 'test.csv', 'train.csv', 'val.csv', 'test', 'train', 'val']\n","True\n","True\n"]}]},{"cell_type":"code","source":["# Define Dataset Class for Test Set\n","class TestDataset(torch.utils.data.Dataset):\n","    def __init__(self, csv_file, image_dir, transform=None):\n","        self.data = pd.read_csv(csv_file)\n","        self.image_dir = image_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        img_path = os.path.join(self.image_dir, self.data.iloc[index]['img_path'])\n","        image = Image.open(img_path).convert('RGB')\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, self.data.iloc[index]['image_id']  # Return image + ID\n","\n","# Define Transformations for Test Data\n","transform_test = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","# ========== IMAGE PREPROCESSING FUNCTIONS ==========\n","def ben_graham_preprocess(image):\n","    \"\"\"Ben Graham preprocessing (sharpening with Gaussian Blur).\"\"\"\n","    image = np.array(image)\n","    image = cv2.addWeighted(image, 4, cv2.GaussianBlur(image, (0, 0), 30), -4, 128)\n","    return Image.fromarray(image)\n","\n","def circle_crop(image):\n","    \"\"\"Applies a circular crop to keep the center and remove background.\"\"\"\n","    image = np.array(image)\n","    height, width, _ = image.shape\n","    mask = np.zeros((height, width), dtype=np.uint8)\n","    cv2.circle(mask, (width//2, height//2), min(width, height)//2, 255, -1)\n","    masked_image = cv2.bitwise_and(image, image, mask=mask)\n","    return Image.fromarray(masked_image)\n","\n","def apply_clahe(image):\n","    \"\"\"Applies CLAHE (Contrast Limited Adaptive Histogram Equalization).\"\"\"\n","    image = np.array(image)\n","    lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n","    l, a, b = cv2.split(lab)\n","    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n","    l = clahe.apply(l)\n","    enhanced_lab = cv2.merge((l, a, b))\n","    enhanced_image = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2RGB)\n","    return Image.fromarray(enhanced_image)\n","\n","# Define Functions for Ensemble Learning:\n","\n","# Majority Voting (Max Voting)\n","def majority_voting(predictions_list):\n","    \"\"\"Perform Majority Voting across multiple model predictions.\"\"\"\n","    final_predictions = []\n","    for i in range(len(predictions_list[0])):\n","        preds = [pred[i] for pred in predictions_list]\n","        final_predictions.append(Counter(preds).most_common(1)[0][0])\n","    return np.array(final_predictions)\n","\n","# Weighted Averaging\n","\n","def weighted_average(predictions_list, weights):\n","    \"\"\"Perform Weighted Averaging of multiple model predictions.\"\"\"\n","    predictions_array = np.array(predictions_list)  # Convert list to NumPy array\n","\n","    if predictions_array.ndim == 1:  # If predictions are 1D, reshape them\n","        predictions_array = predictions_array.reshape(1, -1)\n","\n","    final_predictions = np.average(predictions_array, axis=0, weights=weights)\n","    return np.argmax(final_predictions, axis=0)  # Ensure correct axis\n","\n","\n","# Load Trained Models\n","def load_model(model_name, checkpoint_path):\n","    \"\"\"Load a trained model from checkpoint, ensuring it matches training architecture.\"\"\"\n","    if model_name == \"resnet18\":\n","        model = models.resnet18(weights=None)  # No need to load pretrained weights again\n","        model.fc = torch.nn.Linear(512, 5)  # Match output layer\n","\n","    elif model_name == \"resnet34\":\n","        model = models.resnet34(weights=None)\n","        model.fc = torch.nn.Linear(512, 5)\n","\n","    elif model_name == \"densenet121\":\n","        model = models.densenet121(weights=None)\n","        model.classifier = torch.nn.Linear(1024, 5)\n","\n","    elif model_name == \"efficientnet_b0\":\n","        model = models.efficientnet_b0(weights=None)\n","        model.classifier = torch.nn.Linear(1280, 5)\n","\n","    elif model_name == \"vgg16\":\n","        model = models.vgg16(weights=None)\n","        model.classifier[6] = torch.nn.Linear(4096, 5)\n","\n","    else:\n","        raise ValueError(\"Invalid model name\")\n","\n","    # ðŸ”¹ Load the model state dict\n","    state_dict = torch.load(checkpoint_path, map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # ðŸ”¹ Check if the model has a `backbone` (used during training)\n","    if \"backbone.conv1.weight\" in state_dict:\n","        model = torch.nn.Sequential(\n","            torch.nn.Identity(),  # Dummy layer\n","            model\n","        )\n","\n","    model.load_state_dict(state_dict, strict=False)  # Allow missing keys if necessary\n","    model.eval()  # Set to evaluation mode\n","    return model\n","\n","# Run Predictions\n","def get_predictions(model, dataloader, device):\n","    \"\"\"Generate predictions for test set using a given model.\"\"\"\n","    model.to(device)\n","    all_preds = []\n","\n","    with torch.no_grad():\n","        for images, _ in dataloader:\n","            images = images.to(device)\n","            outputs = model(images)\n","            preds = torch.argmax(outputs, dim=1)\n","            all_preds.extend(preds.cpu().numpy())\n","\n","    return np.array(all_preds)\n","\n","# Main Script\n","if __name__ == '__main__':\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # Define test dataset & dataloader\n","    test_dataset = TestDataset('./DeepDRiD/test.csv', './DeepDRiD/test/', transform_test)\n","    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","    # Load models\n","    model_paths = {\n","        \"resnet18\": \"./model_task_b_resnet18.pth\",\n","        \"resnet34\": \"./model_task_b_resnet34.pth\",\n","        \"densenet121\": \"./model_task_b_densenet121.pth\",\n","        \"efficientnet_b0\": \"./model_task_b_efficientnet_b0.pth\",\n","        \"vgg16\": \"./model_task_b_vgg16.pth\"\n","    }\n","\n","    models = {name: load_model(name, path) for name, path in model_paths.items()}\n","\n","    # Generate predictions for each model\n","    predictions_list = []\n","    for model_name, model in models.items():\n","        print(f\"Generating predictions for {model_name}...\")\n","        predictions = get_predictions(model, test_loader, device)\n","        predictions_list.append(predictions)\n","\n","    # Perform Majority Voting\n","    majority_preds = majority_voting(predictions_list)\n","\n","    # Normalize the Kappa Scores\n","    kappa_scores = [0.8714, 0.8644, 0.8554, 0.8314, 0.8283]  # our best Kappa scores\n","    normalized_weights = [k / sum(kappa_scores) for k in kappa_scores]\n","    print('normalized weights',normalized_weights)\n","\n","    # Perform Weighted Averaging\n","    #weights = [0.25, 0.25, 0.2, 0.15, 0.15]\n","    weights = normalized_weights\n","    weighted_preds = weighted_average(predictions_list, weights)\n","\n","    # Save Final Predictions\n","    submission_df = pd.read_csv('./DeepDRiD/sample_submission.csv')\n","    submission_df['TARGET'] = majority_preds\n","    submission_df.to_csv('./sample_submission_task_d_majority.csv', index=False)\n","    print(\"Saved Majority Voting predictions to sample_submission_task_d_majority.csv\")\n","\n","    submission_df['TARGET'] = weighted_preds\n","    submission_df.to_csv('./sample_submission_task_d_weighted.csv', index=False)\n","    print(\"Saved Weighted Averaging predictions to sample_submission_task_d_weighted.csv\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EpCOqdmvqzZl","executionInfo":{"status":"ok","timestamp":1735904068431,"user_tz":-120,"elapsed":626247,"user":{"displayName":"Amir sard","userId":"05229660649413556744"}},"outputId":"7f7e9980-94f6-4f66-e827-a0e6e68582c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-17-6857e60ccc9f>:79: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = torch.load(checkpoint_path, map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","<ipython-input-17-6857e60ccc9f>:79: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = torch.load(checkpoint_path, map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","<ipython-input-17-6857e60ccc9f>:79: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = torch.load(checkpoint_path, map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","<ipython-input-17-6857e60ccc9f>:79: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = torch.load(checkpoint_path, map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"]},{"output_type":"stream","name":"stdout","text":["Generating predictions for resnet18...\n","Generating predictions for resnet34...\n","Generating predictions for densenet121...\n","Generating predictions for efficientnet_b0...\n","Generating predictions for vgg16...\n","normalized weights [0.20499188407160837, 0.20334517396316074, 0.20122797525229955, 0.19558211202333625, 0.19485285468959518]\n","Saved Majority Voting predictions to sample_submission_task_d_majority.csv\n","Saved Weighted Averaging predictions to sample_submission_task_d_weighted.csv\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"QqgiW7Ymq7zV"},"execution_count":null,"outputs":[]}]}