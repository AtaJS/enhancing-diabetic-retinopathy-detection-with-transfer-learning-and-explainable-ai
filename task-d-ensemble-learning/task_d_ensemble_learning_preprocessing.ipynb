{"cells":[{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3166,"status":"ok","timestamp":1735908050581,"user":{"displayName":"Amir sard","userId":"05229660649413556744"},"user_tz":-120},"id":"H-pUeVgXF8-T"},"outputs":[],"source":["import cv2\n","\n","import copy\n","import os\n","import random\n","import sys\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from PIL import Image\n","from sklearn.metrics import cohen_kappa_score, precision_score, recall_score, accuracy_score\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import models, transforms\n","from torchvision.transforms.functional import to_pil_image\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1697,"status":"ok","timestamp":1735908054344,"user":{"displayName":"Amir sard","userId":"05229660649413556744"},"user_tz":-120},"id":"7fymX2C9GHX3","outputId":"cd1e75ba-2c39-45ad-99c6-c8ffe20669fd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","['sample_submission.csv', 'test.csv', 'train.csv', 'val.csv', 'test', 'train', 'val']\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/MyDrive/Colab Notebooks/DeepLearning_Final_Project_2024')\n","print(os.listdir('DeepDRiD'))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"WXd9d0xaF5Fz"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training with new preprocessing techniques...\n"]},{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30.8M/30.8M [00:00\u003c00:00, 52.0MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 1/10\n","Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [24:50\u003c00:00, 29.82s/ batch, lr=1.0e-04, Loss=0.9391]\n","[Train] Kappa: 0.6908 Accuracy: 0.5658 Precision: 0.5701 Recall: 0.5658 Loss: 1.0943\n","[Train] Class 0: Precision: 0.7634, Recall: 0.8333\n","[Train] Class 1: Precision: 0.4911, Recall: 0.4583\n","[Train] Class 2: Precision: 0.3571, Recall: 0.3750\n","[Train] Class 3: Precision: 0.5298, Recall: 0.6667\n","[Train] Class 4: Precision: 0.6552, Recall: 0.1583\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [04:03\u003c00:00, 14.30s/ batch]\n","[Val] Kappa: 0.7581 Accuracy: 0.6075 Precision: 0.5807 Recall: 0.6075\n","\n","Epoch 2/10\n","Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [17:56\u003c00:00, 21.53s/ batch, lr=1.0e-04, Loss=0.6811]\n","[Train] Kappa: 0.8671 Accuracy: 0.7783 Precision: 0.7779 Recall: 0.7783 Loss: 0.6214\n","[Train] Class 0: Precision: 0.8787, Recall: 0.9861\n","[Train] Class 1: Precision: 0.7860, Recall: 0.7500\n","[Train] Class 2: Precision: 0.7228, Recall: 0.6083\n","[Train] Class 3: Precision: 0.6806, Recall: 0.8792\n","[Train] Class 4: Precision: 0.7636, Recall: 0.3500\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [02:00\u003c00:00,  7.06s/ batch]\n","[Val] Kappa: 0.7518 Accuracy: 0.5750 Precision: 0.5350 Recall: 0.5750\n","\n","Epoch 3/10\n","Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [17:55\u003c00:00, 21.52s/ batch, lr=1.0e-04, Loss=0.4015]\n","[Train] Kappa: 0.9344 Accuracy: 0.8867 Precision: 0.8855 Recall: 0.8867 Loss: 0.4045\n","[Train] Class 0: Precision: 0.9372, Recall: 0.9944\n","[Train] Class 1: Precision: 0.8952, Recall: 0.8542\n","[Train] Class 2: Precision: 0.8312, Recall: 0.8208\n","[Train] Class 3: Precision: 0.8648, Recall: 0.8792\n","[Train] Class 4: Precision: 0.8611, Recall: 0.7750\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [01:59\u003c00:00,  7.04s/ batch]\n","[Val] Kappa: 0.7513 Accuracy: 0.5875 Precision: 0.5612 Recall: 0.5875\n","\n","Epoch 4/10\n","Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [17:44\u003c00:00, 21.30s/ batch, lr=1.0e-04, Loss=0.1665]\n","[Train] Kappa: 0.9695 Accuracy: 0.9433 Precision: 0.9434 Recall: 0.9433 Loss: 0.2359\n","[Train] Class 0: Precision: 0.9593, Recall: 0.9833\n","[Train] Class 1: Precision: 0.9532, Recall: 0.9333\n","[Train] Class 2: Precision: 0.9319, Recall: 0.9125\n","[Train] Class 3: Precision: 0.9203, Recall: 0.9625\n","[Train] Class 4: Precision: 0.9455, Recall: 0.8667\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [01:58\u003c00:00,  6.97s/ batch]\n","[Val] Kappa: 0.7605 Accuracy: 0.6100 Precision: 0.5764 Recall: 0.6100\n","\n","Epoch 5/10\n","Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [17:44\u003c00:00, 21.30s/ batch, lr=1.0e-04, Loss=0.1186]\n","[Train] Kappa: 0.9753 Accuracy: 0.9683 Precision: 0.9684 Recall: 0.9683 Loss: 0.1420\n","[Train] Class 0: Precision: 0.9807, Recall: 0.9889\n","[Train] Class 1: Precision: 0.9664, Recall: 0.9583\n","[Train] Class 2: Precision: 0.9576, Recall: 0.9417\n","[Train] Class 3: Precision: 0.9555, Recall: 0.9833\n","[Train] Class 4: Precision: 0.9828, Recall: 0.9500\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [01:58\u003c00:00,  6.96s/ batch]\n","[Val] Kappa: 0.7766 Accuracy: 0.6225 Precision: 0.5923 Recall: 0.6225\n","\n","Epoch 6/10\n","Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [17:53\u003c00:00, 21.47s/ batch, lr=1.0e-04, Loss=0.1271]\n","[Train] Kappa: 0.9848 Accuracy: 0.9758 Precision: 0.9759 Recall: 0.9758 Loss: 0.1011\n","[Train] Class 0: Precision: 0.9945, Recall: 0.9972\n","[Train] Class 1: Precision: 0.9661, Recall: 0.9500\n","[Train] Class 2: Precision: 0.9506, Recall: 0.9625\n","[Train] Class 3: Precision: 0.9874, Recall: 0.9833\n","[Train] Class 4: Precision: 0.9669, Recall: 0.9750\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [02:01\u003c00:00,  7.13s/ batch]\n","[Val] Kappa: 0.7706 Accuracy: 0.6275 Precision: 0.6026 Recall: 0.6275\n","\n","Epoch 7/10\n","Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [17:49\u003c00:00, 21.39s/ batch, lr=1.0e-04, Loss=0.0370]\n","[Train] Kappa: 0.9856 Accuracy: 0.9808 Precision: 0.9808 Recall: 0.9808 Loss: 0.0814\n","[Train] Class 0: Precision: 0.9863, Recall: 1.0000\n","[Train] Class 1: Precision: 0.9748, Recall: 0.9667\n","[Train] Class 2: Precision: 0.9664, Recall: 0.9583\n","[Train] Class 3: Precision: 0.9958, Recall: 0.9875\n","[Train] Class 4: Precision: 0.9752, Recall: 0.9833\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [01:58\u003c00:00,  6.99s/ batch]\n","[Val] Kappa: 0.7821 Accuracy: 0.6325 Precision: 0.6166 Recall: 0.6325\n","\n","Epoch 8/10\n","Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [17:54\u003c00:00, 21.50s/ batch, lr=1.0e-04, Loss=0.0526]\n","[Train] Kappa: 0.9848 Accuracy: 0.9758 Precision: 0.9759 Recall: 0.9758 Loss: 0.0917\n","[Train] Class 0: Precision: 0.9861, Recall: 0.9861\n","[Train] Class 1: Precision: 0.9703, Recall: 0.9542\n","[Train] Class 2: Precision: 0.9506, Recall: 0.9625\n","[Train] Class 3: Precision: 0.9834, Recall: 0.9875\n","[Train] Class 4: Precision: 0.9917, Recall: 0.9917\n","Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [02:06\u003c00:00,  7.47s/ batch]\n","[Val] Kappa: 0.7715 Accuracy: 0.5950 Precision: 0.5649 Recall: 0.5950\n","\n","Epoch 9/10\n","Training:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [11:51\u003c06:03, 21.37s/ batch, lr=1.0e-04, Loss=0.0165]"]}],"source":["# Hyper Parameters\n","batch_size = 24\n","num_classes = 5  # 5 DR levels\n","learning_rate = 0.0001\n","num_epochs = 20\n","\n","\n","class RetinopathyDataset(Dataset):\n","    def __init__(self, ann_file, image_dir, transform=None, mode='single', test=False):\n","        self.ann_file = ann_file\n","        self.image_dir = image_dir\n","        self.transform = transform\n","\n","        self.test = test\n","        self.mode = mode\n","\n","        if self.mode == 'single':\n","            self.data = self.load_data()\n","        else:\n","            self.data = self.load_data_dual()\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        if self.mode == 'single':\n","            return self.get_item(index)\n","        else:\n","            return self.get_item_dual(index)\n","\n","    # 1. single image\n","    def load_data(self):\n","        df = pd.read_csv(self.ann_file)\n","\n","        data = []\n","        for _, row in df.iterrows():\n","            file_info = dict()\n","            file_info['img_path'] = os.path.join(self.image_dir, row['img_path'])\n","            if not self.test:\n","                file_info['dr_level'] = int(row['patient_DR_Level'])\n","            data.append(file_info)\n","        return data\n","\n","    def get_item(self, index):\n","        data = self.data[index]\n","        img = Image.open(data['img_path']).convert('RGB')\n","        if self.transform:\n","            img = self.transform(img)\n","\n","        if not self.test:\n","            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n","            return img, label\n","        else:\n","            return img\n","\n","    # 2. dual image\n","    def load_data_dual(self):\n","        df = pd.read_csv(self.ann_file)\n","\n","        df['prefix'] = df['image_id'].str.split('_').str[0]  # The patient id of each image\n","        df['suffix'] = df['image_id'].str.split('_').str[1].str[0]  # The left or right eye\n","        grouped = df.groupby(['prefix', 'suffix'])\n","\n","        data = []\n","        for (prefix, suffix), group in grouped:\n","            file_info = dict()\n","            file_info['img_path1'] = os.path.join(self.image_dir, group.iloc[0]['img_path'])\n","            file_info['img_path2'] = os.path.join(self.image_dir, group.iloc[1]['img_path'])\n","            if not self.test:\n","                file_info['dr_level'] = int(group.iloc[0]['patient_DR_Level'])\n","            data.append(file_info)\n","        return data\n","\n","    def get_item_dual(self, index):\n","        data = self.data[index]\n","        img1 = Image.open(data['img_path1']).convert('RGB')\n","        img2 = Image.open(data['img_path2']).convert('RGB')\n","\n","        if self.transform:\n","            img1 = self.transform(img1)\n","            img2 = self.transform(img2)\n","\n","        if not self.test:\n","            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n","            return [img1, img2], label\n","        else:\n","            return [img1, img2]\n","\n","\n","class CutOut(object):\n","    def __init__(self, mask_size, p=0.5):\n","        self.mask_size = mask_size\n","        self.p = p\n","\n","    def __call__(self, img):\n","        if np.random.rand() \u003e self.p:\n","            return img\n","\n","        # Ensure the image is a tensor\n","        if not isinstance(img, torch.Tensor):\n","            raise TypeError('Input image must be a torch.Tensor')\n","\n","        # Get height and width of the image\n","        h, w = img.shape[1], img.shape[2]\n","        mask_size_half = self.mask_size // 2\n","        offset = 1 if self.mask_size % 2 == 0 else 0\n","\n","        cx = np.random.randint(mask_size_half, w + offset - mask_size_half)\n","        cy = np.random.randint(mask_size_half, h + offset - mask_size_half)\n","\n","        xmin, xmax = cx - mask_size_half, cx + mask_size_half + offset\n","        ymin, ymax = cy - mask_size_half, cy + mask_size_half + offset\n","        xmin, xmax = max(0, xmin), min(w, xmax)\n","        ymin, ymax = max(0, ymin), min(h, ymax)\n","\n","        img[:, ymin:ymax, xmin:xmax] = 0\n","        return img\n","\n","\n","class SLORandomPad:\n","    def __init__(self, size):\n","        self.size = size\n","\n","    def __call__(self, img):\n","        pad_width = max(0, self.size[0] - img.width)\n","        pad_height = max(0, self.size[1] - img.height)\n","        pad_left = random.randint(0, pad_width)\n","        pad_top = random.randint(0, pad_height)\n","        pad_right = pad_width - pad_left\n","        pad_bottom = pad_height - pad_top\n","        return transforms.functional.pad(img, (pad_left, pad_top, pad_right, pad_bottom))\n","\n","\n","class FundRandomRotate:\n","    def __init__(self, prob, degree):\n","        self.prob = prob\n","        self.degree = degree\n","\n","    def __call__(self, img):\n","        if random.random() \u003c self.prob:\n","            angle = random.uniform(-self.degree, self.degree)\n","            return transforms.functional.rotate(img, angle)\n","        return img\n","\n","# ========== NEW IMAGE PREPROCESSING FUNCTIONS ==========\n","def ben_graham_preprocess(image):\n","    \"\"\"Ben Graham preprocessing (sharpening with Gaussian Blur).\"\"\"\n","    image = np.array(image)\n","    image = cv2.addWeighted(image, 4, cv2.GaussianBlur(image, (0, 0), 30), -4, 128)\n","    return Image.fromarray(image)\n","\n","def circle_crop(image):\n","    \"\"\"Applies a circular crop to keep the center and remove background.\"\"\"\n","    image = np.array(image)\n","    height, width, _ = image.shape\n","    mask = np.zeros((height, width), dtype=np.uint8)\n","    cv2.circle(mask, (width//2, height//2), min(width, height)//2, 255, -1)\n","    masked_image = cv2.bitwise_and(image, image, mask=mask)\n","    return Image.fromarray(masked_image)\n","\n","def apply_clahe(image):\n","    \"\"\"Applies CLAHE (Contrast Limited Adaptive Histogram Equalization).\"\"\"\n","    image = np.array(image)\n","    lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n","    l, a, b = cv2.split(lab)\n","    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n","    l = clahe.apply(l)\n","    enhanced_lab = cv2.merge((l, a, b))\n","    enhanced_image = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2RGB)\n","    return Image.fromarray(enhanced_image)\n","\n","transform_train = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.Lambda(ben_graham_preprocess),\n","    transforms.Lambda(circle_crop),\n","    transforms.Lambda(apply_clahe),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.Lambda(ben_graham_preprocess),\n","    transforms.Lambda(circle_crop),\n","    transforms.Lambda(apply_clahe),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","def train_model(model, train_loader, val_loader, device, criterion, optimizer, lr_scheduler, num_epochs=25,\n","                checkpoint_path='model.pth'):\n","    best_model = model.state_dict()\n","    best_epoch = None\n","    best_val_kappa = -1.0  # Initialize the best kappa score\n","\n","    for epoch in range(1, num_epochs + 1):\n","        print(f'\\nEpoch {epoch}/{num_epochs}')\n","        running_loss = []\n","        all_preds = []\n","        all_labels = []\n","\n","        model.train()\n","\n","        with tqdm(total=len(train_loader), desc=f'Training', unit=' batch', file=sys.stdout) as pbar:\n","            for images, labels in train_loader:\n","                if not isinstance(images, list):\n","                    images = images.to(device)  # single image case\n","                else:\n","                    images = [x.to(device) for x in images]  # dual images case\n","\n","                labels = labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                outputs = model(images)\n","                loss = criterion(outputs, labels.long())\n","\n","                loss.backward()\n","                optimizer.step()\n","\n","                preds = torch.argmax(outputs, 1)\n","                all_preds.extend(preds.cpu().numpy())\n","                all_labels.extend(labels.cpu().numpy())\n","\n","                running_loss.append(loss.item())\n","\n","                pbar.set_postfix({'lr': f'{optimizer.param_groups[0][\"lr\"]:.1e}', 'Loss': f'{loss.item():.4f}'})\n","                pbar.update(1)\n","\n","        lr_scheduler.step()\n","\n","        epoch_loss = sum(running_loss) / len(running_loss)\n","\n","        train_metrics = compute_metrics(all_preds, all_labels, per_class=True)\n","        kappa, accuracy, precision, recall = train_metrics[:4]\n","\n","        print(f'[Train] Kappa: {kappa:.4f} Accuracy: {accuracy:.4f} '\n","              f'Precision: {precision:.4f} Recall: {recall:.4f} Loss: {epoch_loss:.4f}')\n","\n","        if len(train_metrics) \u003e 4:\n","            precision_per_class, recall_per_class = train_metrics[4:]\n","            for i, (precision, recall) in enumerate(zip(precision_per_class, recall_per_class)):\n","                print(f'[Train] Class {i}: Precision: {precision:.4f}, Recall: {recall:.4f}')\n","\n","        # Evaluation on the validation set at the end of each epoch\n","        val_metrics = evaluate_model(model, val_loader, device)\n","        val_kappa, val_accuracy, val_precision, val_recall = val_metrics[:4]\n","        print(f'[Val] Kappa: {val_kappa:.4f} Accuracy: {val_accuracy:.4f} '\n","              f'Precision: {val_precision:.4f} Recall: {val_recall:.4f}')\n","\n","        if val_kappa \u003e best_val_kappa:\n","            best_val_kappa = val_kappa\n","            best_epoch = epoch\n","            best_model = model.state_dict()\n","            torch.save(best_model, checkpoint_path)\n","\n","    print(f'[Val] Best kappa: {best_val_kappa:.4f}, Epoch {best_epoch}')\n","\n","    return model\n","\n","\n","def evaluate_model(model, test_loader, device, test_only=False, prediction_path='./test_predictions.csv'):\n","    model.eval()\n","\n","    all_preds = []\n","    all_labels = []\n","    all_image_ids = []\n","\n","    with tqdm(total=len(test_loader), desc=f'Evaluating', unit=' batch', file=sys.stdout) as pbar:\n","        for i, data in enumerate(test_loader):\n","\n","            if test_only:\n","                images = data\n","            else:\n","                images, labels = data\n","\n","            if not isinstance(images, list):\n","                images = images.to(device)  # single image case\n","            else:\n","                images = [x.to(device) for x in images]  # dual images case\n","\n","            with torch.no_grad():\n","                outputs = model(images)\n","                preds = torch.argmax(outputs, 1)\n","\n","            if not isinstance(images, list):\n","                # single image case\n","                all_preds.extend(preds.cpu().numpy())\n","                image_ids = [\n","                    os.path.basename(test_loader.dataset.data[idx]['img_path']) for idx in\n","                    range(i * test_loader.batch_size, i * test_loader.batch_size + len(images))\n","                ]\n","                all_image_ids.extend(image_ids)\n","                if not test_only:\n","                    all_labels.extend(labels.numpy())\n","            else:\n","                # dual images case\n","                for k in range(2):\n","                    all_preds.extend(preds.cpu().numpy())\n","                    image_ids = [\n","                        os.path.basename(test_loader.dataset.data[idx][f'img_path{k + 1}']) for idx in\n","                        range(i * test_loader.batch_size, i * test_loader.batch_size + len(images[k]))\n","                    ]\n","                    all_image_ids.extend(image_ids)\n","                    if not test_only:\n","                        all_labels.extend(labels.numpy())\n","\n","            pbar.update(1)\n","\n","    # Save predictions to csv file for Kaggle online evaluation\n","    if test_only:\n","        df = pd.DataFrame({\n","            'ID': all_image_ids,\n","            'TARGET': all_preds\n","        })\n","        df.to_csv(prediction_path, index=False)\n","        print(f'[Test] Save predictions to {os.path.abspath(prediction_path)}')\n","    else:\n","        metrics = compute_metrics(all_preds, all_labels)\n","        return metrics\n","\n","\n","def compute_metrics(preds, labels, per_class=False):\n","    kappa = cohen_kappa_score(labels, preds, weights='quadratic')\n","    accuracy = accuracy_score(labels, preds)\n","    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n","    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n","\n","    # Calculate and print precision and recall for each class\n","    if per_class:\n","        precision_per_class = precision_score(labels, preds, average=None, zero_division=0)\n","        recall_per_class = recall_score(labels, preds, average=None, zero_division=0)\n","        return kappa, accuracy, precision, recall, precision_per_class, recall_per_class\n","\n","    return kappa, accuracy, precision, recall\n","\n","\n","\n","\n","\n","# ========== TRAINING WITH NEW PREPROCESSING ==========\n","if __name__ == '__main__':\n","    print(\"Training with new preprocessing techniques...\")\n","\n","    # Load dataset with new transformations\n","    train_dataset = RetinopathyDataset('./DeepDRiD/train.csv', './DeepDRiD/train/', transform_train, mode='single')\n","    val_dataset = RetinopathyDataset('./DeepDRiD/val.csv', './DeepDRiD/val/', transform_test, mode='single')\n","    test_dataset = RetinopathyDataset('./DeepDRiD/test.csv', './DeepDRiD/test/', transform_test, mode='single', test=True)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","    # Choose the best model from Task (b) (e.g., DenseNet121)\n","    model = models.densenet121(weights=\"IMAGENET1K_V1\")\n","    model.classifier = torch.nn.Linear(1024, 5)  # Adjust for 5-class classification\n","\n","    # Move model to GPU\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model = model.to(device)\n","\n","    # Define optimizer and loss function\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n","\n","    # Train model\n","    model = train_model(\n","        model=model,\n","        train_loader=train_loader,\n","        val_loader=val_loader,\n","        device=device,\n","        criterion=criterion,\n","        optimizer=optimizer,\n","        lr_scheduler=lr_scheduler,\n","        num_epochs=10,\n","        checkpoint_path='./model_task_d_preprocessing.pth'  # ðŸ”¹ New name for clarity\n","    )\n","\n","    # Save test predictions\n","    print(\"Saving test predictions for preprocessing experiment...\")\n","    evaluate_model(\n","        model=model,\n","        test_loader=test_loader,\n","        device=device,\n","        test_only=True,\n","        prediction_path='./sample_submission_task_d_preprocessing.csv'  # ðŸ”¹ New name for clarity\n","    )\n","\n","    print(\"âœ… Task (d) - Preprocessing Experiments Completed!\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOuLmo49Bm/WfWpTYjL+NRt","gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}