{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm","authorship_tag":"ABX9TyNbM5ZgS39tSEWpgQMYlSsB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import copy\n","import os\n","import random\n","import sys\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pandas as pd\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import cohen_kappa_score, precision_score, recall_score, accuracy_score\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import models, transforms\n","from torchvision.transforms.functional import to_pil_image\n","from tqdm import tqdm\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A6OMsmuSSGMr","executionInfo":{"status":"ok","timestamp":1735813252952,"user_tz":-120,"elapsed":29455,"user":{"displayName":"Amir sard","userId":"05229660649413556744"}},"outputId":"cf361388-e395-4d51-95d9-4ac688d31bdf"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["os.chdir('/content/drive/MyDrive/Colab Notebooks/DeepLearning_Final_Project_2024')\n","print(os.listdir('DeepDRiD'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zjmfPmOpSTaU","executionInfo":{"status":"ok","timestamp":1735813254054,"user_tz":-120,"elapsed":1105,"user":{"displayName":"Amir sard","userId":"05229660649413556744"}},"outputId":"b3c2bc85-e790-4151-f985-e9788fe98ccf"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["['sample_submission.csv', 'test.csv', 'train.csv', 'val.csv', 'test', 'train', 'val']\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"UgzydvhsKgiA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735814377571,"user_tz":-120,"elapsed":1112727,"user":{"displayName":"Amir sard","userId":"05229660649413556744"}},"outputId":"b2e07bd7-b2f9-4e9a-8903-52a534c16918"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using ResNet18 with SE Blocks...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 104MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Fine-tuning the attention-enhanced model on DeepDRiD dataset...\n","\n","Epoch 1/15\n","Training: 100%|██████████| 50/50 [08:50<00:00, 10.61s/ batch, lr=1.0e-04, Loss=1.2632]\n","[Train] Kappa: 0.3302 Accuracy: 0.3850 Precision: 0.3485 Recall: 0.3850 Loss: 1.4290\n","[Train] Class 0: Precision: 0.5393, Recall: 0.7806\n","[Train] Class 1: Precision: 0.2567, Recall: 0.2792\n","[Train] Class 2: Precision: 0.2511, Recall: 0.2333\n","[Train] Class 3: Precision: 0.3472, Recall: 0.2083\n","[Train] Class 4: Precision: 0.1569, Recall: 0.0667\n","Evaluating: 100%|██████████| 17/17 [02:52<00:00, 10.18s/ batch]\n","[Val] Kappa: 0.5075 Accuracy: 0.5250 Precision: 0.4043 Recall: 0.5250\n","\n","Epoch 2/15\n","Training: 100%|██████████| 50/50 [00:12<00:00,  4.04 batch/s, lr=1.0e-04, Loss=0.9666]\n","[Train] Kappa: 0.5967 Accuracy: 0.5083 Precision: 0.4342 Recall: 0.5083 Loss: 1.1992\n","[Train] Class 0: Precision: 0.7732, Recall: 0.9472\n","[Train] Class 1: Precision: 0.3574, Recall: 0.4958\n","[Train] Class 2: Precision: 0.2645, Recall: 0.1333\n","[Train] Class 3: Precision: 0.3894, Recall: 0.4917\n","[Train] Class 4: Precision: 0.0000, Recall: 0.0000\n","Evaluating: 100%|██████████| 17/17 [00:03<00:00,  4.77 batch/s]\n","[Val] Kappa: 0.5570 Accuracy: 0.5250 Precision: 0.4575 Recall: 0.5250\n","\n","Epoch 3/15\n","Training: 100%|██████████| 50/50 [00:12<00:00,  3.91 batch/s, lr=1.0e-04, Loss=1.0225]\n","[Train] Kappa: 0.7040 Accuracy: 0.5425 Precision: 0.5069 Recall: 0.5425 Loss: 1.1137\n","[Train] Class 0: Precision: 0.7995, Recall: 0.9306\n","[Train] Class 1: Precision: 0.4672, Recall: 0.5042\n","[Train] Class 2: Precision: 0.2840, Recall: 0.2000\n","[Train] Class 3: Precision: 0.4171, Recall: 0.6083\n","[Train] Class 4: Precision: 0.3333, Recall: 0.0083\n","Evaluating: 100%|██████████| 17/17 [00:03<00:00,  4.39 batch/s]\n","[Val] Kappa: 0.6769 Accuracy: 0.5925 Precision: 0.6095 Recall: 0.5925\n","\n","Epoch 4/15\n","Training: 100%|██████████| 50/50 [00:12<00:00,  3.98 batch/s, lr=1.0e-04, Loss=1.0360]\n","[Train] Kappa: 0.7428 Accuracy: 0.5858 Precision: 0.5340 Recall: 0.5858 Loss: 1.0155\n","[Train] Class 0: Precision: 0.8099, Recall: 0.9583\n","[Train] Class 1: Precision: 0.5165, Recall: 0.5208\n","[Train] Class 2: Precision: 0.3916, Recall: 0.2708\n","[Train] Class 3: Precision: 0.4703, Recall: 0.6917\n","[Train] Class 4: Precision: 0.1538, Recall: 0.0167\n","Evaluating: 100%|██████████| 17/17 [00:03<00:00,  5.25 batch/s]\n","[Val] Kappa: 0.7624 Accuracy: 0.5950 Precision: 0.5345 Recall: 0.5950\n","\n","Epoch 5/15\n","Training: 100%|██████████| 50/50 [00:12<00:00,  3.96 batch/s, lr=1.0e-04, Loss=0.8821]\n","[Train] Kappa: 0.7733 Accuracy: 0.6183 Precision: 0.5803 Recall: 0.6183 Loss: 0.9312\n","[Train] Class 0: Precision: 0.8329, Recall: 0.9694\n","[Train] Class 1: Precision: 0.5697, Recall: 0.5792\n","[Train] Class 2: Precision: 0.4091, Recall: 0.3000\n","[Train] Class 3: Precision: 0.5194, Recall: 0.7250\n","[Train] Class 4: Precision: 0.3077, Recall: 0.0667\n","Evaluating: 100%|██████████| 17/17 [00:03<00:00,  4.92 batch/s]\n","[Val] Kappa: 0.7733 Accuracy: 0.6150 Precision: 0.5551 Recall: 0.6150\n","\n","Epoch 6/15\n","Training: 100%|██████████| 50/50 [00:13<00:00,  3.84 batch/s, lr=1.0e-04, Loss=0.9484]\n","[Train] Kappa: 0.7870 Accuracy: 0.6142 Precision: 0.5853 Recall: 0.6142 Loss: 0.9170\n","[Train] Class 0: Precision: 0.8171, Recall: 0.9556\n","[Train] Class 1: Precision: 0.6161, Recall: 0.5750\n","[Train] Class 2: Precision: 0.4301, Recall: 0.3333\n","[Train] Class 3: Precision: 0.4954, Recall: 0.6708\n","[Train] Class 4: Precision: 0.3182, Recall: 0.1167\n","Evaluating: 100%|██████████| 17/17 [00:03<00:00,  4.52 batch/s]\n","[Val] Kappa: 0.6849 Accuracy: 0.6150 Precision: 0.5969 Recall: 0.6150\n","\n","Epoch 7/15\n","Training: 100%|██████████| 50/50 [00:12<00:00,  3.94 batch/s, lr=1.0e-04, Loss=0.7727]\n","[Train] Kappa: 0.8198 Accuracy: 0.6525 Precision: 0.6349 Recall: 0.6525 Loss: 0.8699\n","[Train] Class 0: Precision: 0.8706, Recall: 0.9722\n","[Train] Class 1: Precision: 0.6516, Recall: 0.6625\n","[Train] Class 2: Precision: 0.4525, Recall: 0.3375\n","[Train] Class 3: Precision: 0.5189, Recall: 0.6875\n","[Train] Class 4: Precision: 0.4912, Recall: 0.2333\n","Evaluating: 100%|██████████| 17/17 [00:03<00:00,  4.97 batch/s]\n","[Val] Kappa: 0.7865 Accuracy: 0.6250 Precision: 0.6316 Recall: 0.6250\n","\n","Epoch 8/15\n","Training: 100%|██████████| 50/50 [00:12<00:00,  3.96 batch/s, lr=1.0e-04, Loss=0.8677]\n","[Train] Kappa: 0.8275 Accuracy: 0.6792 Precision: 0.6654 Recall: 0.6792 Loss: 0.8256\n","[Train] Class 0: Precision: 0.8627, Recall: 0.9778\n","[Train] Class 1: Precision: 0.6571, Recall: 0.6708\n","[Train] Class 2: Precision: 0.5204, Recall: 0.4250\n","[Train] Class 3: Precision: 0.5696, Recall: 0.7333\n","[Train] Class 4: Precision: 0.5714, Recall: 0.2000\n","Evaluating: 100%|██████████| 17/17 [00:03<00:00,  5.04 batch/s]\n","[Val] Kappa: 0.7992 Accuracy: 0.6025 Precision: 0.6109 Recall: 0.6025\n","\n","Epoch 9/15\n","Training: 100%|██████████| 50/50 [00:13<00:00,  3.83 batch/s, lr=1.0e-04, Loss=0.9102]\n","[Train] Kappa: 0.8257 Accuracy: 0.6775 Precision: 0.6691 Recall: 0.6775 Loss: 0.8115\n","[Train] Class 0: Precision: 0.8766, Recall: 0.9667\n","[Train] Class 1: Precision: 0.6957, Recall: 0.6000\n","[Train] Class 2: Precision: 0.5455, Recall: 0.5500\n","[Train] Class 3: Precision: 0.5564, Recall: 0.6167\n","[Train] Class 4: Precision: 0.4659, Recall: 0.3417\n","Evaluating: 100%|██████████| 17/17 [00:03<00:00,  4.92 batch/s]\n","[Val] Kappa: 0.7656 Accuracy: 0.6125 Precision: 0.5951 Recall: 0.6125\n","\n","Epoch 10/15\n","Training: 100%|██████████| 50/50 [00:12<00:00,  3.91 batch/s, lr=1.0e-04, Loss=0.6513]\n","[Train] Kappa: 0.8564 Accuracy: 0.7258 Precision: 0.7206 Recall: 0.7258 Loss: 0.7269\n","[Train] Class 0: Precision: 0.8997, Recall: 0.9722\n","[Train] Class 1: Precision: 0.7225, Recall: 0.6833\n","[Train] Class 2: Precision: 0.5819, Recall: 0.5625\n","[Train] Class 3: Precision: 0.6272, Recall: 0.7292\n","[Train] Class 4: Precision: 0.6438, Recall: 0.3917\n","Evaluating: 100%|██████████| 17/17 [00:03<00:00,  5.35 batch/s]\n","[Val] Kappa: 0.7889 Accuracy: 0.6575 Precision: 0.6407 Recall: 0.6575\n","\n","Epoch 11/15\n","Training: 100%|██████████| 50/50 [00:12<00:00,  3.91 batch/s, lr=1.0e-05, Loss=0.7032]\n","[Train] Kappa: 0.8804 Accuracy: 0.7558 Precision: 0.7519 Recall: 0.7558 Loss: 0.6845\n","[Train] Class 0: Precision: 0.9026, Recall: 0.9778\n","[Train] Class 1: Precision: 0.7479, Recall: 0.7292\n","[Train] Class 2: Precision: 0.6489, Recall: 0.6083\n","[Train] Class 3: Precision: 0.6544, Recall: 0.7417\n","[Train] Class 4: Precision: 0.7089, Recall: 0.4667\n","Evaluating: 100%|██████████| 17/17 [00:03<00:00,  4.51 batch/s]\n","[Val] Kappa: 0.7785 Accuracy: 0.6450 Precision: 0.6202 Recall: 0.6450\n","\n","Epoch 12/15\n","Training: 100%|██████████| 50/50 [00:12<00:00,  4.03 batch/s, lr=1.0e-05, Loss=0.7246]\n","[Train] Kappa: 0.8886 Accuracy: 0.7683 Precision: 0.7649 Recall: 0.7683 Loss: 0.6348\n","[Train] Class 0: Precision: 0.9098, Recall: 0.9806\n","[Train] Class 1: Precision: 0.7713, Recall: 0.7167\n","[Train] Class 2: Precision: 0.6214, Recall: 0.6292\n","[Train] Class 3: Precision: 0.7099, Recall: 0.7750\n","[Train] Class 4: Precision: 0.7143, Recall: 0.5000\n","Evaluating: 100%|██████████| 17/17 [00:03<00:00,  4.35 batch/s]\n","[Val] Kappa: 0.7701 Accuracy: 0.6425 Precision: 0.6064 Recall: 0.6425\n","\n","Epoch 13/15\n","Training: 100%|██████████| 50/50 [00:12<00:00,  3.93 batch/s, lr=1.0e-05, Loss=0.5600]\n","[Train] Kappa: 0.8824 Accuracy: 0.7575 Precision: 0.7529 Recall: 0.7575 Loss: 0.6267\n","[Train] Class 0: Precision: 0.9188, Recall: 0.9750\n","[Train] Class 1: Precision: 0.7647, Recall: 0.7583\n","[Train] Class 2: Precision: 0.6547, Recall: 0.6083\n","[Train] Class 3: Precision: 0.6429, Recall: 0.7125\n","[Train] Class 4: Precision: 0.6484, Recall: 0.4917\n","Evaluating: 100%|██████████| 17/17 [00:03<00:00,  4.49 batch/s]\n","[Val] Kappa: 0.7917 Accuracy: 0.6425 Precision: 0.6202 Recall: 0.6425\n","\n","Epoch 14/15\n","Training: 100%|██████████| 50/50 [00:12<00:00,  3.98 batch/s, lr=1.0e-05, Loss=0.4528]\n","[Train] Kappa: 0.8893 Accuracy: 0.7692 Precision: 0.7653 Recall: 0.7692 Loss: 0.6261\n","[Train] Class 0: Precision: 0.9197, Recall: 0.9861\n","[Train] Class 1: Precision: 0.8000, Recall: 0.7333\n","[Train] Class 2: Precision: 0.6345, Recall: 0.6292\n","[Train] Class 3: Precision: 0.6844, Recall: 0.7500\n","[Train] Class 4: Precision: 0.6559, Recall: 0.5083\n","Evaluating: 100%|██████████| 17/17 [00:03<00:00,  4.76 batch/s]\n","[Val] Kappa: 0.7830 Accuracy: 0.6350 Precision: 0.6104 Recall: 0.6350\n","\n","Epoch 15/15\n","Training: 100%|██████████| 50/50 [00:12<00:00,  3.92 batch/s, lr=1.0e-05, Loss=0.5838]\n","[Train] Kappa: 0.8766 Accuracy: 0.7725 Precision: 0.7683 Recall: 0.7725 Loss: 0.5940\n","[Train] Class 0: Precision: 0.9028, Recall: 0.9806\n","[Train] Class 1: Precision: 0.7941, Recall: 0.7875\n","[Train] Class 2: Precision: 0.6789, Recall: 0.6167\n","[Train] Class 3: Precision: 0.6618, Recall: 0.7583\n","[Train] Class 4: Precision: 0.7051, Recall: 0.4583\n","Evaluating: 100%|██████████| 17/17 [00:03<00:00,  4.87 batch/s]\n","[Val] Kappa: 0.7863 Accuracy: 0.6500 Precision: 0.6266 Recall: 0.6500\n","[Val] Best kappa: 0.7992, Epoch 8\n","Saving test set predictions...\n","Evaluating: 100%|██████████| 17/17 [02:55<00:00, 10.32s/ batch]\n","[Test] Save predictions to /content/drive/MyDrive/Colab Notebooks/DeepLearning_Final_Project_2024/sample_submission_task_c.csv\n","Task (c) complete! Predictions saved to './sample_submission_task_c.csv'.\n"]}],"source":["# Hyper Parameters\n","batch_size = 24\n","num_classes = 5  # 5 DR levels\n","learning_rate = 0.0001\n","num_epochs = 20\n","\n","\n","class RetinopathyDataset(Dataset):\n","    def __init__(self, ann_file, image_dir, transform=None, mode='single', test=False):\n","        self.ann_file = ann_file\n","        self.image_dir = image_dir\n","        self.transform = transform\n","\n","        self.test = test\n","        self.mode = mode\n","\n","        if self.mode == 'single':\n","            self.data = self.load_data()\n","        else:\n","            self.data = self.load_data_dual()\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        if self.mode == 'single':\n","            return self.get_item(index)\n","        else:\n","            return self.get_item_dual(index)\n","\n","    # 1. single image\n","    def load_data(self):\n","        df = pd.read_csv(self.ann_file)\n","\n","        data = []\n","        for _, row in df.iterrows():\n","            file_info = dict()\n","            file_info['img_path'] = os.path.join(self.image_dir, row['img_path'])\n","            if not self.test:\n","                file_info['dr_level'] = int(row['patient_DR_Level'])\n","            data.append(file_info)\n","        return data\n","\n","    def get_item(self, index):\n","        data = self.data[index]\n","        img = Image.open(data['img_path']).convert('RGB')\n","        if self.transform:\n","            img = self.transform(img)\n","\n","        if not self.test:\n","            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n","            return img, label\n","        else:\n","            return img\n","\n","    # 2. dual image\n","    def load_data_dual(self):\n","        df = pd.read_csv(self.ann_file)\n","\n","        df['prefix'] = df['image_id'].str.split('_').str[0]  # The patient id of each image\n","        df['suffix'] = df['image_id'].str.split('_').str[1].str[0]  # The left or right eye\n","        grouped = df.groupby(['prefix', 'suffix'])\n","\n","        data = []\n","        for (prefix, suffix), group in grouped:\n","            file_info = dict()\n","            file_info['img_path1'] = os.path.join(self.image_dir, group.iloc[0]['img_path'])\n","            file_info['img_path2'] = os.path.join(self.image_dir, group.iloc[1]['img_path'])\n","            if not self.test:\n","                file_info['dr_level'] = int(group.iloc[0]['patient_DR_Level'])\n","            data.append(file_info)\n","        return data\n","\n","    def get_item_dual(self, index):\n","        data = self.data[index]\n","        img1 = Image.open(data['img_path1']).convert('RGB')\n","        img2 = Image.open(data['img_path2']).convert('RGB')\n","\n","        if self.transform:\n","            img1 = self.transform(img1)\n","            img2 = self.transform(img2)\n","\n","        if not self.test:\n","            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n","            return [img1, img2], label\n","        else:\n","            return [img1, img2]\n","\n","\n","class CutOut(object):\n","    def __init__(self, mask_size, p=0.5):\n","        self.mask_size = mask_size\n","        self.p = p\n","\n","    def __call__(self, img):\n","        if np.random.rand() > self.p:\n","            return img\n","\n","        # Ensure the image is a tensor\n","        if not isinstance(img, torch.Tensor):\n","            raise TypeError('Input image must be a torch.Tensor')\n","\n","        # Get height and width of the image\n","        h, w = img.shape[1], img.shape[2]\n","        mask_size_half = self.mask_size // 2\n","        offset = 1 if self.mask_size % 2 == 0 else 0\n","\n","        cx = np.random.randint(mask_size_half, w + offset - mask_size_half)\n","        cy = np.random.randint(mask_size_half, h + offset - mask_size_half)\n","\n","        xmin, xmax = cx - mask_size_half, cx + mask_size_half + offset\n","        ymin, ymax = cy - mask_size_half, cy + mask_size_half + offset\n","        xmin, xmax = max(0, xmin), min(w, xmax)\n","        ymin, ymax = max(0, ymin), min(h, ymax)\n","\n","        img[:, ymin:ymax, xmin:xmax] = 0\n","        return img\n","\n","\n","class SLORandomPad:\n","    def __init__(self, size):\n","        self.size = size\n","\n","    def __call__(self, img):\n","        pad_width = max(0, self.size[0] - img.width)\n","        pad_height = max(0, self.size[1] - img.height)\n","        pad_left = random.randint(0, pad_width)\n","        pad_top = random.randint(0, pad_height)\n","        pad_right = pad_width - pad_left\n","        pad_bottom = pad_height - pad_top\n","        return transforms.functional.pad(img, (pad_left, pad_top, pad_right, pad_bottom))\n","\n","\n","class FundRandomRotate:\n","    def __init__(self, prob, degree):\n","        self.prob = prob\n","        self.degree = degree\n","\n","    def __call__(self, img):\n","        if random.random() < self.prob:\n","            angle = random.uniform(-self.degree, self.degree)\n","            return transforms.functional.rotate(img, angle)\n","        return img\n","\n","\n","transform_train = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.RandomCrop((210, 210)),\n","    SLORandomPad((224, 224)),\n","    FundRandomRotate(prob=0.5, degree=30),\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.RandomVerticalFlip(p=0.5),\n","    transforms.ColorJitter(brightness=(0.1, 0.9)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","\n","def train_model(model, train_loader, val_loader, device, criterion, optimizer, lr_scheduler, num_epochs=25,\n","                checkpoint_path='model.pth'):\n","    best_model = model.state_dict()\n","    best_epoch = None\n","    best_val_kappa = -1.0  # Initialize the best kappa score\n","\n","    for epoch in range(1, num_epochs + 1):\n","        print(f'\\nEpoch {epoch}/{num_epochs}')\n","        running_loss = []\n","        all_preds = []\n","        all_labels = []\n","\n","        model.train()\n","\n","        with tqdm(total=len(train_loader), desc=f'Training', unit=' batch', file=sys.stdout) as pbar:\n","            for images, labels in train_loader:\n","                if not isinstance(images, list):\n","                    images = images.to(device)  # single image case\n","                else:\n","                    images = [x.to(device) for x in images]  # dual images case\n","\n","                labels = labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                outputs = model(images)\n","                loss = criterion(outputs, labels.long())\n","\n","                loss.backward()\n","                optimizer.step()\n","\n","                preds = torch.argmax(outputs, 1)\n","                all_preds.extend(preds.cpu().numpy())\n","                all_labels.extend(labels.cpu().numpy())\n","\n","                running_loss.append(loss.item())\n","\n","                pbar.set_postfix({'lr': f'{optimizer.param_groups[0][\"lr\"]:.1e}', 'Loss': f'{loss.item():.4f}'})\n","                pbar.update(1)\n","\n","        lr_scheduler.step()\n","\n","        epoch_loss = sum(running_loss) / len(running_loss)\n","\n","        train_metrics = compute_metrics(all_preds, all_labels, per_class=True)\n","        kappa, accuracy, precision, recall = train_metrics[:4]\n","\n","        print(f'[Train] Kappa: {kappa:.4f} Accuracy: {accuracy:.4f} '\n","              f'Precision: {precision:.4f} Recall: {recall:.4f} Loss: {epoch_loss:.4f}')\n","\n","        if len(train_metrics) > 4:\n","            precision_per_class, recall_per_class = train_metrics[4:]\n","            for i, (precision, recall) in enumerate(zip(precision_per_class, recall_per_class)):\n","                print(f'[Train] Class {i}: Precision: {precision:.4f}, Recall: {recall:.4f}')\n","\n","        # Evaluation on the validation set at the end of each epoch\n","        val_metrics = evaluate_model(model, val_loader, device)\n","        val_kappa, val_accuracy, val_precision, val_recall = val_metrics[:4]\n","        print(f'[Val] Kappa: {val_kappa:.4f} Accuracy: {val_accuracy:.4f} '\n","              f'Precision: {val_precision:.4f} Recall: {val_recall:.4f}')\n","\n","        if val_kappa > best_val_kappa:\n","            best_val_kappa = val_kappa\n","            best_epoch = epoch\n","            best_model = model.state_dict()\n","            torch.save(best_model, checkpoint_path)\n","\n","    print(f'[Val] Best kappa: {best_val_kappa:.4f}, Epoch {best_epoch}')\n","\n","    return model\n","\n","\n","def evaluate_model(model, test_loader, device, test_only=False, prediction_path='./test_predictions.csv'):\n","    model.eval()\n","\n","    all_preds = []\n","    all_labels = []\n","    all_image_ids = []\n","\n","    with tqdm(total=len(test_loader), desc=f'Evaluating', unit=' batch', file=sys.stdout) as pbar:\n","        for i, data in enumerate(test_loader):\n","\n","            if test_only:\n","                images = data\n","            else:\n","                images, labels = data\n","\n","            if not isinstance(images, list):\n","                images = images.to(device)  # single image case\n","            else:\n","                images = [x.to(device) for x in images]  # dual images case\n","\n","            with torch.no_grad():\n","                outputs = model(images)\n","                preds = torch.argmax(outputs, 1)\n","\n","            if not isinstance(images, list):\n","                # single image case\n","                all_preds.extend(preds.cpu().numpy())\n","                image_ids = [\n","                    os.path.basename(test_loader.dataset.data[idx]['img_path']) for idx in\n","                    range(i * test_loader.batch_size, i * test_loader.batch_size + len(images))\n","                ]\n","                all_image_ids.extend(image_ids)\n","                if not test_only:\n","                    all_labels.extend(labels.numpy())\n","            else:\n","                # dual images case\n","                for k in range(2):\n","                    all_preds.extend(preds.cpu().numpy())\n","                    image_ids = [\n","                        os.path.basename(test_loader.dataset.data[idx][f'img_path{k + 1}']) for idx in\n","                        range(i * test_loader.batch_size, i * test_loader.batch_size + len(images[k]))\n","                    ]\n","                    all_image_ids.extend(image_ids)\n","                    if not test_only:\n","                        all_labels.extend(labels.numpy())\n","\n","            pbar.update(1)\n","\n","    # Save predictions to csv file for Kaggle online evaluation\n","    if test_only:\n","        df = pd.DataFrame({\n","            'ID': all_image_ids,\n","            'TARGET': all_preds\n","        })\n","        df.to_csv(prediction_path, index=False)\n","        print(f'[Test] Save predictions to {os.path.abspath(prediction_path)}')\n","    else:\n","        metrics = compute_metrics(all_preds, all_labels)\n","        return metrics\n","\n","\n","def compute_metrics(preds, labels, per_class=False):\n","    kappa = cohen_kappa_score(labels, preds, weights='quadratic')\n","    accuracy = accuracy_score(labels, preds)\n","    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n","    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n","\n","    # Calculate and print precision and recall for each class\n","    if per_class:\n","        precision_per_class = precision_score(labels, preds, average=None, zero_division=0)\n","        recall_per_class = recall_score(labels, preds, average=None, zero_division=0)\n","        return kappa, accuracy, precision, recall, precision_per_class, recall_per_class\n","\n","    return kappa, accuracy, precision, recall\n","\n","\n","class MyModel(nn.Module):\n","    def __init__(self, num_classes=5, dropout_rate=0.5):\n","        super().__init__()\n","\n","        # Use pretrained=False since we're loading custom weights\n","\n","        #self.backbone = models.resnet18(pretrained=False)\n","        self.backbone = models.Resnet18(pretrained=False)\n","        state_dict = torch.load('./pretrained/Resnet18.pth')\n","        info = self.backbone.load_state_dict(state_dict, strict=False)\n","        print('missing keys:', info.missing_keys)  # Normal: FC layer will be missing\n","        print('unexpected keys:', info.unexpected_keys)\n","\n","        # Replace the classifier layer\n","        self.backbone.fc = nn.Sequential(\n","            nn.Linear(512, 256),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(p=dropout_rate),\n","            nn.Linear(256, 128),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(p=dropout_rate),\n","            nn.Linear(128, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.backbone(x)\n","\n","\n","class MyDualModel(nn.Module):\n","    def __init__(self, num_classes=5, dropout_rate=0.5):\n","        super().__init__()\n","\n","        backbone = models.Resnet18(pretrained=True)\n","        backbone.fc = nn.Identity()\n","\n","        # Here the two backbones will have the same structure but unshared weights\n","        self.backbone1 = copy.deepcopy(backbone)\n","        self.backbone2 = copy.deepcopy(backbone)\n","\n","        self.fc = nn.Sequential(\n","            nn.Linear(512 * 2, 256),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(p=dropout_rate),\n","            nn.Linear(256, 128),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(p=dropout_rate),\n","            nn.Linear(128, num_classes)\n","        )\n","\n","    def forward(self, images):\n","        image1, image2 = images\n","\n","        x1 = self.backbone1(image1)\n","        x2 = self.backbone2(image2)\n","\n","        x = torch.cat((x1, x2), dim=1)\n","        x = self.fc(x)\n","        return x\n","\n","\n","class SEBlock(nn.Module):\n","    def __init__(self, in_channels, reduction=16):\n","        super(SEBlock, self).__init__()\n","        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.fc1 = nn.Linear(in_channels, in_channels // reduction)\n","        self.fc2 = nn.Linear(in_channels // reduction, in_channels)\n","\n","    def forward(self, x):\n","        batch, channels, _, _ = x.size()\n","        se = self.global_avg_pool(x).view(batch, channels)\n","        se = F.relu(self.fc1(se))\n","        se = torch.sigmoid(self.fc2(se)).view(batch, channels, 1, 1)\n","        return x * se\n","\n","class AttentionResNet18(nn.Module):\n","    def __init__(self, num_classes=5, dropout_rate=0.5):\n","        super().__init__()\n","        # Load ResNet18 backbone\n","        self.backbone = models.resnet18(pretrained=True)\n","\n","        # Add SE blocks after each block in the ResNet\n","        self.backbone.layer1[0].se_block = SEBlock(in_channels=64)\n","        self.backbone.layer2[0].se_block = SEBlock(in_channels=128)\n","        self.backbone.layer3[0].se_block = SEBlock(in_channels=256)\n","        self.backbone.layer4[0].se_block = SEBlock(in_channels=512)\n","\n","        # Replace the classifier layer\n","        self.backbone.fc = nn.Sequential(\n","            nn.Linear(512, 256),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(p=dropout_rate),\n","            nn.Linear(256, 128),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(p=dropout_rate),\n","            nn.Linear(128, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        # Forward pass through backbone\n","        x = self.backbone(x)\n","        return x\n","\n","\n","if __name__ == '__main__':\n","\n","    # Define the attention-enhanced model --------------------------------------\n","    print(\"Using ResNet18 with SE Blocks...\")\n","    model = AttentionResNet18(num_classes=5, dropout_rate=0.5)\n","\n","    # Move model to device\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model = model.to(device)\n","\n","    # Fine-tune on DeepDRiD ----------------------------------------------------\n","    print(\"Fine-tuning the attention-enhanced model on DeepDRiD dataset...\")\n","    train_dataset = RetinopathyDataset('./DeepDRiD/train.csv', './DeepDRiD/train/', transform_train, mode='single')\n","    val_dataset = RetinopathyDataset('./DeepDRiD/val.csv', './DeepDRiD/val/', transform_test, mode='single')\n","    test_dataset = RetinopathyDataset('./DeepDRiD/test.csv', './DeepDRiD/test/', transform_test, mode='single', test=True)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n","\n","    # Train the model ----------------------------------------------------------\n","    model = train_model(\n","        model=model,\n","        train_loader=train_loader,\n","        val_loader=val_loader,\n","        device=device,\n","        criterion=criterion,\n","        optimizer=optimizer,\n","        lr_scheduler=lr_scheduler,\n","        num_epochs=15,  # Adjust as needed\n","        checkpoint_path='./model_task_c_attention.pth'\n","    )\n","\n","    # Predictions for Kaggle ---------------------------------------------------\n","    print(\"Saving test set predictions...\")\n","    evaluate_model(\n","        model=model,\n","        test_loader=test_loader,\n","        device=device,\n","        test_only=True,\n","        prediction_path='./sample_submission_task_c.csv'\n","    )\n","\n","    print(\"Task (c) complete! Predictions saved to './sample_submission_task_c.csv'.\")"]}]}